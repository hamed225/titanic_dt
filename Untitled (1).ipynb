{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0            1         0       3    male  22.0      1      0   7.2500        S\n",
      "1            2         1       1  female  38.0      1      0  71.2833        C\n",
      "2            3         1       3  female  26.0      0      0   7.9250        S\n",
      "3            4         1       1  female  35.0      1      0  53.1000        S\n",
      "4            5         0       3    male  35.0      0      0   8.0500        S\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Delete columns not being used \n",
    "cols = ['Name','Ticket','Cabin']\n",
    "df = df.drop(cols, axis = 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 62.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Set index to 'PassengerId'\n",
    "df = df.set_index('PassengerId')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 1 to 891\n",
      "Data columns (total 8 columns):\n",
      "Survived    712 non-null int64\n",
      "Pclass      712 non-null category\n",
      "Sex         712 non-null category\n",
      "Age         712 non-null float64\n",
      "SibSp       712 non-null int64\n",
      "Parch       712 non-null int64\n",
      "Fare        712 non-null float64\n",
      "Embarked    712 non-null category\n",
      "dtypes: category(3), float64(2), int64(3)\n",
      "memory usage: 35.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create categorical variables\n",
    "numerics = ['Age','SibSp','Parch','Fare']\n",
    "categories = ['Pclass','Sex','Embarked']\n",
    "df[categories] = df[categories].astype('category')\n",
    "\n",
    "# Drop null values\n",
    "df = df.dropna()\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived   Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  \\\n",
      "PassengerId                                                              \n",
      "1                   0  22.0      1      0   7.2500         0         0   \n",
      "2                   1  38.0      1      0  71.2833         1         0   \n",
      "3                   1  26.0      0      0   7.9250         0         0   \n",
      "4                   1  35.0      1      0  53.1000         1         0   \n",
      "5                   0  35.0      0      0   8.0500         0         0   \n",
      "\n",
      "             Pclass_3  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
      "PassengerId                                                           \n",
      "1                   1           0         1           0           0   \n",
      "2                   0           1         0           1           0   \n",
      "3                   1           1         0           0           0   \n",
      "4                   0           1         0           0           0   \n",
      "5                   1           0         1           0           0   \n",
      "\n",
      "             Embarked_S  \n",
      "PassengerId              \n",
      "1                     1  \n",
      "2                     0  \n",
      "3                     1  \n",
      "4                     1  \n",
      "5                     1  \n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables\n",
    "dummy_df = pd.get_dummies(df, columns=['Pclass','Sex', 'Embarked'])\n",
    "print(dummy_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712,)\n",
      "(712, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create Predictor and Response variables\n",
    "\n",
    "labels = dummy_df['Survived'].values\n",
    "print(labels.shape)\n",
    "\n",
    "features = dummy_df.loc[:, dummy_df.columns != 'Survived'].values\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Two DecisionTreeClassifier Models. One Scaled and One Not Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML packages \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state = 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline for scaled model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "steps = [('scaler' , StandardScaler()),\n",
    "         ('dt', DecisionTreeClassifier())]\n",
    "\n",
    "Pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dt', 'dt__class_weight', 'dt__criterion', 'dt__max_depth', 'dt__max_features', 'dt__max_leaf_nodes', 'dt__min_impurity_decrease', 'dt__min_impurity_split', 'dt__min_samples_leaf', 'dt__min_samples_split', 'dt__min_weight_fraction_leaf', 'dt__presort', 'dt__random_state', 'dt__splitter', 'memory', 'scaler', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'steps', 'verbose']\n"
     ]
    }
   ],
   "source": [
    "#Create parameter dictionaries\n",
    "\n",
    "print(sorted(Pipeline.get_params().keys()))\n",
    "\n",
    "# Parameters for unscaled model\n",
    "param_dist_dt = {\"max_depth\": np.arange(1,12),\n",
    "                 \"min_samples_split\" : np.linspace(0.1, 1.0, 100, endpoint=True),\n",
    "              \"max_features\": list(range(1,X_train.shape[1])),\n",
    "              \"min_samples_leaf\": np.linspace(0.1, 0.5, 100, endpoint=True),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Parameters for scaled model\n",
    "param_dist_dt_cv = {\"dt__max_depth\": np.arange(1,12),\n",
    "              \"dt__min_samples_split\" : np.linspace(0.1, 1.0, 100, endpoint=True),\n",
    "              \"dt__max_features\": list(range(1,X_train.shape[1])),\n",
    "              \"dt__min_samples_leaf\": np.linspace(0.1, 0.5, 100, endpoint=True),\n",
    "              \"dt__criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'min_samples_split': 0.2181818181818182, 'min_samples_leaf': 0.19292929292929295, 'max_features': 8, 'max_depth': 9, 'criterion': 'gini'}\n",
      "Best score is 0.7811244979919679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomas.m.sugg\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Unscaled model RandomizedSearchCV\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_cv = RandomizedSearchCV(dt, param_dist_dt, cv = 10)\n",
    "dt_cv.fit(X_train,y_train)\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(dt_cv.best_params_))\n",
    "print(\"Best score is {}\".format(dt_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7757009345794392\n"
     ]
    }
   ],
   "source": [
    "# Unscaled predictions\n",
    "y_pred_cv = dt_cv.predict(X_test)\n",
    "print(\"Accuracy: \" , accuracy_score(y_test, y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomas.m.sugg\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'dt__min_samples_split': 0.5909090909090909, 'dt__min_samples_leaf': 0.3343434343434344, 'dt__max_features': 8, 'dt__max_depth': 5, 'dt__criterion': 'entropy'}\n",
      "Best score is 0.7811244979919679\n"
     ]
    }
   ],
   "source": [
    "# Scaled Model RandomizedSearchCV\n",
    "dt_cv2 = RandomizedSearchCV(Pipeline, param_dist_dt_cv, cv = 10)\n",
    "dt_cv2.fit(X_train,y_train)\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(dt_cv2.best_params_))\n",
    "print(\"Best score is {}\".format(dt_cv2.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Validation Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7757009345794392\n"
     ]
    }
   ],
   "source": [
    "# Scaled predictions\n",
    "y_pred_cv2 = dt_cv2.predict(X_test)\n",
    "print(\"Accuracy: \" , accuracy_score(y_test, y_pred_cv2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on the Holdout Dataset and Convert them to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
      "0          892       3    male  34.5      0      0   7.8292        Q\n",
      "1          893       3  female  47.0      1      0   7.0000        S\n",
      "2          894       2    male  62.0      0      0   9.6875        Q\n",
      "3          895       3    male  27.0      0      0   8.6625        S\n",
      "4          896       3  female  22.0      1      1  12.2875        S\n"
     ]
    }
   ],
   "source": [
    "holdout = pd.read_csv('test.csv')\n",
    "holdout = holdout.drop(cols, axis = 1)\n",
    "print(holdout.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 7 columns):\n",
      "Pclass      418 non-null int64\n",
      "Sex         418 non-null object\n",
      "Age         332 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Fare        417 non-null float64\n",
      "Embarked    418 non-null object\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 26.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Set index to 'PassengerId'\n",
    "holdout = holdout.set_index('PassengerId')\n",
    "print(holdout.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 7 columns):\n",
      "Pclass      418 non-null category\n",
      "Sex         418 non-null category\n",
      "Age         332 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Fare        417 non-null float64\n",
      "Embarked    418 non-null category\n",
      "dtypes: category(3), float64(2), int64(2)\n",
      "memory usage: 17.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "holdout[categories] = holdout[categories].astype('category')\n",
    "print(holdout.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
      "PassengerId                                                              \n",
      "892          34.5      0      0   7.8292         0         0         1   \n",
      "893          47.0      1      0   7.0000         0         0         1   \n",
      "894          62.0      0      0   9.6875         0         1         0   \n",
      "895          27.0      0      0   8.6625         0         0         1   \n",
      "896          22.0      1      1  12.2875         0         0         1   \n",
      "\n",
      "             Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
      "PassengerId                                                            \n",
      "892                   0         1           0           1           0  \n",
      "893                   1         0           0           0           1  \n",
      "894                   0         1           0           1           0  \n",
      "895                   0         1           0           0           1  \n",
      "896                   1         0           0           0           1  \n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables\n",
    "dummy_df_holdout = pd.get_dummies(holdout, columns=['Pclass','Sex', 'Embarked'])\n",
    "print(dummy_df_holdout.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 12 columns):\n",
      "Age           418 non-null float64\n",
      "SibSp         418 non-null int64\n",
      "Parch         418 non-null int64\n",
      "Fare          418 non-null float64\n",
      "Pclass_1      418 non-null uint8\n",
      "Pclass_2      418 non-null uint8\n",
      "Pclass_3      418 non-null uint8\n",
      "Sex_female    418 non-null uint8\n",
      "Sex_male      418 non-null uint8\n",
      "Embarked_C    418 non-null uint8\n",
      "Embarked_Q    418 non-null uint8\n",
      "Embarked_S    418 non-null uint8\n",
      "dtypes: float64(2), int64(2), uint8(8)\n",
      "memory usage: 19.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dummy_df_holdout = dummy_df_holdout.fillna(dummy_df_holdout.mean())\n",
    "print(dummy_df_holdout.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "holdout_pred = dt_cv2.predict(dummy_df_holdout)\n",
    "print(holdout_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived\n",
      "PassengerId          \n",
      "892                 0\n",
      "893                 1\n",
      "894                 0\n",
      "895                 0\n",
      "896                 1\n",
      "897                 0\n",
      "898                 1\n",
      "899                 0\n",
      "900                 1\n",
      "901                 0\n",
      "902                 0\n",
      "903                 0\n",
      "904                 1\n",
      "905                 0\n",
      "906                 1\n",
      "907                 1\n",
      "908                 0\n",
      "909                 0\n",
      "910                 1\n",
      "911                 1\n",
      "912                 0\n",
      "913                 0\n",
      "914                 1\n",
      "915                 0\n",
      "916                 1\n",
      "917                 0\n",
      "918                 1\n",
      "919                 0\n",
      "920                 0\n",
      "921                 0\n",
      "...               ...\n",
      "1280                0\n",
      "1281                0\n",
      "1282                0\n",
      "1283                1\n",
      "1284                0\n",
      "1285                0\n",
      "1286                0\n",
      "1287                1\n",
      "1288                0\n",
      "1289                1\n",
      "1290                0\n",
      "1291                0\n",
      "1292                1\n",
      "1293                0\n",
      "1294                1\n",
      "1295                0\n",
      "1296                0\n",
      "1297                0\n",
      "1298                0\n",
      "1299                0\n",
      "1300                1\n",
      "1301                1\n",
      "1302                1\n",
      "1303                1\n",
      "1304                1\n",
      "1305                0\n",
      "1306                1\n",
      "1307                0\n",
      "1308                0\n",
      "1309                0\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "Id = np.arange(892, 1310)\n",
    "y_pred_df = pd.DataFrame(holdout_pred, Id)\n",
    "y_pred_df.index.name = 'PassengerId'\n",
    "y_pred_df.columns = [\"Survived\"]\n",
    "print(y_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
